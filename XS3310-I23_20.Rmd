---
title: "XS3310 Teoría Estadística"
subtitle: "I Semestre 2022"
author: ""
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

class: center, middle

# ¿Qué hemos visto hasta ahora?

Introducción a la Estadística Bayesiana: filosofía, historia y un poco de cálculo. Distribuciones previas informativas y conjugadas.

# ¿Qué vamos a discutir hoy?

Distribuciones previas (Jeffreys), inferencia Bayesiana.


---

# Previas no informativas
	
Este tipo de previa es posiblemente el más utilizado en la práctica. Con modelos relativamente simples utilizar una previa no informativa por lo general brinda resultados muy similares a los resultados frecuentistas, mientras que con modelos jerárquicos más complejos los resultados sí pueden ser más distintos. No obstante, la mayoría del tiempo en que se quiere hacer inferencia sobre parámetros desconocidos no se tiene mucha información al respecto, aparte de un posible rango en donde se puedan encontrar; por esto es más atractivo utilizar una previa no informativa. Diremos que una previa es no informativa si le da la libertad a los datos de encontrar los mejores valores de los parámetros. 
	
Por mucho tiempo se tuvo la idea de que las previas no informativas eran exclusivamente las uniformes, pues asignaban probabilidades iguales a cualquier parámetro. Sin embargo, hay quienes criticaron esto, como Fisher, diciendo que no es posible que la uniforme sea siempre no informativa. 

---

# Previas no informativas
	

El argumento de Fisher era algo así:
	
>	Supongamos que tenemos un parámetro desconocido $\theta$ que representa la probabilidad de éxito de un experimento Bernoulli. Supongamos que no sabemos nada de $\theta$ entonces decimos que $\theta \sim Unif(0,1)$. Ahora, si no sabemos nada de $\theta$ entonces tampoco sabemos nada de $\lambda = -\ln(\theta)$, por lo que también podríamos preferir una previa uniforme para $\lambda$. Sería lógico pensar que, mediante las técnicas de transformaciones, la transformación aplicada a la previa de $\theta$ llegue a la previa de $\lambda$. Sin embargo hay un problema lógico pues si aplicamos las técnicas de transformación a la previa de $\theta$ no vamos a llegar a la misma previa de $\theta$. Esto sugiere que una distribución uniforme no es un buen ejemplo de una previa no informativa. 

---

# Previas no informativas
	
Un tipo de previa no informativa es la **previa de Jeffreys**. Estas hacen uso de la Información de Fisher, previamente utilizada en el Tema 1. Por lo tanto, si tenemos una muestra aleatoria $X_1 , X_2 , ... , X_n$ de una población con función de densidad $f_{X}(x|\theta)$ entonces la información de Fisher se define como:
	
$$I(\theta) = -E\left[ \frac{\partial^{2} \ln(f_{X}(x|\theta)) }{\partial \theta^{2}} \right]$$
	
Por lo tanto, la previa de Jeffreys se define como:
	
$$\pi_{J}(\theta) = c\sqrt{I(\theta)}$$
	
Donde $c$ es una constante positiva mayor a cero que asegura que esta función de densidad integra a uno. Como $c$ es constante entonces podemos decir que $\pi_{J}(\theta) \propto \sqrt{I(\theta)}$, por lo que muchas veces no nos importa el valor de $c$ para encontrar la distribución a posteriori a partir de la previa de Jeffreys. 

---

# Previas no informativas
	
Ejemplo: Sea $X_1 , X_2 , ... , X_n$ una muestra aleatoria tal que $X_j \sim N(\mu,1)$. Encuentre la previa de Jeffreys para $\mu$. 
	
Solución: Recordemos la función de densidad de una Normal:
	
$$f_{X}(x|\mu) = \sqrt{2\pi} e^{-\frac{(x-\mu)^{2}}{2}}$$
	
Por lo que el logaritmo natural de esta sería:
	
$$\ln(f_{X}(x|\mu))  = \frac{1}{2}\ln(2\pi) - \frac{(x-\mu)^{2}}{2}$$
	
Derivamos dos veces con respecto a $\mu$:
	
$$\frac{\partial \ln(f_{X}(x|\mu)) }{\partial \mu} = x - \mu$$
	
$$\Rightarrow \frac{\partial^{2} \ln(f_{X}(x|\mu)) }{\partial \mu^{2}} = -1$$
	
---

# Previas no informativas
	

Finalmente obtenemos
	
$$I(\mu) = 1$$
	
Por lo tanto, podemos concluir que $\pi_{J}(\theta) \propto 1$, es decir, es proporcional a una constante. Por lo tanto, la previa de Jeffreys para estimar a $\mu$ sería una distribución Uniforme, escogida en un rango bastante amplio. 

Hay un par de puntos importantes de destacar cuando se usa la previa de Jeffreys. El primero de ellos es que no siempre se va a llegar a una función de densidad propia (es decir, una función de densidad que integre a 1 en su dominio). Por lo general se ignora este problema si la posteriori si es propia. Por lo tanto, siempre que se vaya a utilizar una previa impropia hay que revisar que la posteriori sea propia, si no los resultados no tendrían sentido. El segundo punto es un poco más filosófico y trata con el hecho de que las previas se deben elegir antes de ver los datos. La previa de Jeffreys usa la distribución de los datos para encontrar una previa lo que contradice lo que muchos dicen sobre el planteamiento de la previa. 

---
class: center, middle, inverse

# Inferencia Bayesiana

---

## Inferencia Bayesiana


Como en la estadística Bayesiana la posteriori es la distribución que contiene toda la información pertinente sobre $\theta$, los problemas de inferencia estadística se solucionan trabajando con esta distribución. A continuación veremos de manera general los temas del curso pero dentro del enfoque Bayesiano. 

### Estimación puntual
	
En estadística Bayesiana se tiene el inconveniente de que tenemos incertidumbre sobre el parámetro y hay que ver cómo se puede sacar un valor puntual para $\theta$ de toda esta incertidumbre. La respuesta tradicional es buscar el centro de la distribución a posteriori de $\theta$. Por lo tanto, el **estimador de Bayes** más tradicional se define como la media de la distribución a posteriori de $\theta$. Es decir, $\hat{\theta}_{B} = E(\theta|x)$. 
	
---

## Estimación puntual

En los ejemplos que vimos anteriormente donde encontrábamos la distribución a posteriori y calculamos los valores esperados de esta, lo que realmente estábamos haciendo era obteniendo el estimador de Bayes. A estos estimadores se le pueden volver a estudiar todas las propiedades que ya vimos en el curso (Insesgado, Eficiente, Consistente y Suficiente) e incluso comparar contra otros estimadores frecuentistas. 
	
Por lo general, los estimadores puntuales Bayesianos están asociados a una **función de pérdida**, denotada como $\ell(\hat{\theta},\theta)$, que mide la penalización en la que se incurre al utilizar $\hat{\theta}$ para estimar $\theta$. La función de pérdida más común es la de pérdida cuadrática que se define como $\ell(\hat{\theta},\theta) = (\hat{\theta}-\theta)^{2}$. 
	
---

## Estimación puntual

El objetivo es encontrar el valor de $\hat{\theta}$ que minimice $E\left( \ell(\hat{\theta},\theta) \,\middle|\, x \right) = \int \ell(\hat{\theta},\theta) \pi(\theta|x) d\theta$, llamado el riesgo Bayesiano a posteriori. Por lo tanto, podemos ver que el estimador de Bayes que minimiza el riesgo Bayesiano utilizando la función de pérdida cuadrática se obtiene minimizando la expresión
	
$$\int (\hat{\theta}-\theta)^{2} \pi(\theta|x) d\theta = E\left( (\hat{\theta}-\theta)^{2} \,\middle|\, x \right)$$
	
Encontremos el valor de $\hat{\theta}$ que minimiza esta expresión. Primero simplifiquemos la expresión anterior un poco:
	
$$E\left( (\hat{\theta}-\theta)^{2} \,\middle|\, x \right) = E\left( \hat{\theta}^{2} -2\theta\hat{\theta} +\theta^{2} \,\middle|\, x \right) = \hat{\theta}^{2} -2\hat{\theta}E(\theta|x) + E(\theta^{2}|x)$$
	
---

## Estimación puntual

Derivamos esta expresión con respecto a $\hat{\theta}$:
	
$$\frac{\partial }{\partial \hat{\theta}}  E\left( (\hat{\theta}-\theta)^{2} \,\middle|\, x \right) = 2\hat{\theta} - 2E(\theta|x) = 0$$
$$\Rightarrow \hat{\theta} = E(\theta|x)$$
	
Como la segunda derivada es positiva entonces tenemos que $\hat{\theta} = E(\theta|x)$ es el valor que minimiza el riesgo de Bayes con pérdida cuadrática. Este valor es el mismo al estimador de Bayes usualmente utilizando, por lo que podríamos decir que siempre que usemos la media a posteriori como estimador de $\theta$ estamos usando el valor que minimiza el riesgo de Bayes con pérdida cuadrática. Si cambiamos la función de pérdida entonces el estimador de Bayes cambiaría. 
	
---

## Intervalos de credibilidad
	
El análogo Bayesiano a los intervalos de confianza se llama intervalos de credibilidad (o de veracidad). Recordemos que en la estadística frecuentista la interpretación de un intervalo de confianza se hace tratando al intervalo como variable aleatoria, por lo que es incorrecto decir que $\theta$ se encuentra entre tanto y tanto con tanta probabilidad. Sin embargo, en el punto de vista Bayesiano si es posible hacer una conclusión como esa pues tenemos todo un modelo probabilístico a posteriori sobre los posibles valores que podría tomar $\theta$. 
	
Existen dos formas usualmente utilizadas para obtener intervalos de credibilidad. Nosotros nos estaremos enfocando más en generar intervalos del primer tipo ya que los de la segunda forma son más complejos de generar en papel y lápiz.

---

## Intervalos de credibilidad
	
	
* **Intervalos de credibilidad de colas iguales**. Estos son posiblemente los más utilizados en la práctica. Son intervalos de la forma $\left[a,b \right]$ de probabilidad $1-\alpha$, donde $a$ y $b$ se definen mediante las ecuaciones
		
$$P(a < \theta < b|x) = 1-\alpha$$
$$P(\theta \leq a|x) = P(\theta \geq b |x) = \frac{\alpha}{2}$$ 
		
Por lo general están centrados alrededor de la media (si la distribución a posteriori es bastante simétrica). También existen las versiones unilaterales. 
		
* **Intervalos de credibilidad de máxima densidad a posteriori**. Se conocen como intervalos HPD por sus siglas en inglés. Su definición viene dada para un valor de corte $c > 0$ tal que 
		
$$H(c) = \left\lbrace \theta : \pi(\theta|x) \geq c  \right\rbrace$$
		
El valor $c$ se encuentra de forma que $P(\theta \in H(c) | x) = 1- \alpha$. Encontrar este tipo de intervalos equivale a dibujar líneas horizontales en la densidad a posteriori a partir de la moda e ir bajando la línea horizontal (el valor de $c$) hasta que por debajo de esa línea se acumule una probabilidad de $1-\alpha$. 

---

## Intervalos de credibilidad
	
Veremos un ejemplo para in intervalo de credibilidad de colas iguales: 
	
Ejemplo: Sea $X_1 , X_2 , ... , X_n$ una muestra aleatoria tal que $X_j \sim N(\mu,\sigma^2)$, donde $\sigma^{2}$ es conocido. Obtenga un intervalo de credibilidad de colas iguales para $\mu$ de probabilidad $1-\alpha$ utilizando como priori una distribución Uniforme. 
	
Solución: Lo primero que tenemos que hacer es encontrar la distribución a posteriori para $\mu$. Como la priori es uniforme entonces tenemos que 
	
$$\pi(\mu|x) \propto \mathcal{L}(\mu|x) = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{\sum (x_j - \mu)^{2} }{2\sigma^2}} \propto e^{-\frac{\sum (x_j - \mu)^{2} }{2\sigma^2}}$$
	
Trabajando esta expresión un poco tenemos que
	
$$e^{-\frac{\sum (x_j - \mu)^{2} }{2\sigma^2}} = e^{ -\frac{\sum (x_j - \overline{x})^{2} + n(\overline{x} - \mu)^{2}}{2\sigma^2}  }  = e^{ -\frac{\sum (x_j - \overline{x})^{2}}{2\sigma^2}  }e^{ -\frac{ n(\overline{x} - \mu)^{2}}{2\sigma^2}  }  \propto e^{ -\frac{ n(\overline{x} - \mu)^{2}}{2\sigma^2}  }$$

Esta expresión se puede reescribir de la forma $e^{ -\frac{ n(\mu - \overline{x})^{2}}{2\sigma^2}  }$. Este es el núcleo de una distribución Normal para $\mu$ con media $\overline{x}$ y variancia $\frac{\sigma^2}{n}$. Por lo tanto tenemos que
$$\mu|x \sim N\left( \overline{x}, \frac{\sigma^2}{n} \right)$$


---

## Intervalos de credibilidad
	
	
Ahora podemos proceder a encontrar el intervalo de credibilidad. Tenemos que encontrar valores $a$ y $b$ tales que $P(a < \mu < b|x) = 1-\alpha$ y $P(\mu \leq a|x) = P(\mu \geq b |x) = \frac{\alpha}{2}$. Por lo tanto
	
$$P(\mu \leq a|x) = P\left( \frac{\mu - \overline{x}}{\frac{\sigma}{\sqrt{n}}} \leq \frac{a - \overline{x}}{\frac{\sigma}{\sqrt{n}}} \,\middle|\, x \right)  = P\left( Z \leq \frac{\sqrt{n}(a - \overline{x}) }{\sigma} \,\middle|\, x \right)  = \frac{\alpha}{2}$$
	
Esto quiere decir que tenemos que buscar el cuantil de una normal estándar que acumula $\frac{\alpha}{2}$ en su cola derecha. Este valor lo denotamos como $z_{\frac{\alpha}{2}}$ que por simetría es igual a $-z_{1-\frac{\alpha}{2}}$. Por lo tanto 
	
$$\frac{\sqrt{n}(a - \overline{x}) }{\sigma} = -z_{1-\frac{\alpha}{2}}$$
	
$$\Rightarrow a =  \overline{x} -z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}$$

---

## Intervalos de credibilidad
	
			
Si hacemos este procedimiento para encontrar $b$ vamos a obtener que $b = \overline{x} + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}$. Por lo tanto vamos a tener una probabilidad de $1-\alpha$ de encontrar el verdadero valor de $\mu$ en el intervalo $\overline{x} \pm z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}$. Vean que este intervalo es completamente idéntico al intervalo de confianza para $\mu$ frecuentista; inclusive el estimador de Bayes es igual al estimador de máxima verosimilitud para $\mu$. Esto se debe a que se utilizó una priori no informativa para obtener la posteriori, por lo que el resultado a posteriori es muy similar al resultado frecuentista. No obstante, el ejemplo se hizo con propósitos ilustrativos de cómo encontrar un intervalo de credibilidad con colas iguales.

---

## Factor de Bayes
	
Recordemos que nosotros tenemos las hipótesis $H_{0}: \theta \in \Omega_{0}$ contra  $H_{1}: \theta \in \Omega_{1}$. En la estadística frecuentista es imposible calcular las probabilidades de estas hipótesis por lo que tenemos que generar un contraste a partir de ciertos criterios para las probabilidades de Error Tipo I y de Error Tipo II. Sin embargo, en el caso Bayesiano donde tenemos una distribución a posteriori para $\theta$ entonces sí es posible calcular las probabilidades de que $H_0$ o $H_1$ sean ciertos. Es decir, calcularíamos $\alpha_{0} = P(\theta \in \Omega_{0} | x)$ y $\alpha_{1} = P(\theta \in \Omega_{1} | x)$. 
	
Por lo tanto un contraste de hipótesis Bayesiano usualmente se reduce a comparar estas probabilidades y concluir correspondientemente. Podríamos decir que un Bayesiano va a rechazar la hipótesis nula si $\alpha_0  < 0.5$. Aunque es posible obtener la potencia de este contraste, por lo general en estadística Bayesiana no nos preocupamos por estas medidas. Aunque este es el método usual de comparar hipótesis, algunos prefieren hacer una comparación de odds a priori y a posteriori, lo cual produce un contraste un poco distinto. Para esta explicación denotará las probabilidades a priori de $H_0$ y $H_1$ como $\pi_0$ y $\pi_1$, respectivamente. Es decir, $\pi_0 = P(\theta \in \Omega_{0})$ y $\pi_1 = P(\theta \in \Omega_{1})$. 

---

## Factor de Bayes

	
La cantidad $\frac{\alpha_{0}}{\alpha_{1}}$ se define como los *odds* a posteriori de $H_0$ con respecto a $H_1$. Por otro lado podemos definir $\frac{\pi_{0}}{\pi_{1}}$ como los \textit{odds} a priori. Por lo tanto podemos definir la medida 
	
$$B = \frac{\frac{\alpha_{0}}{\alpha_{1}}}{\frac{\pi_{0}}{\pi_{1}}} = \frac{\alpha_{0}\pi_{1}}{\alpha_{1}pi_{0}}$$
	
como los *odds ratio* a favor de $H_0$. Este valor se denomina el **factor de Bayes**. En ocasiones este factor se interpreta como "los odds de $H_0$ con respecto a $H_1$ dados por los datos".  Esta interpretación es válida cuando las hipótesis son simples es decir, cuando $\Omega_{0} = \left\lbrace \theta_0\right\rbrace$ y $\Omega_{1} = \left\lbrace \theta_1\right\rbrace$. En este caso tenemos que 
	
$$\alpha_{0} = P(\theta = \theta_0 |x) = \frac{\mathcal{L}(\theta_0|x)\pi_0}{\mathcal{L}(\theta_0|x)\pi_0 + \mathcal{L}(\theta_1|x)\pi_1}$$
	
$$\alpha_{1} = P(\theta = \theta_1 |x) = \frac{\mathcal{L}(\theta_1|x)\pi_1}{\mathcal{L}(\theta_0|x)\pi_0 + \mathcal{L}(\theta_1|x)\pi_1}$$

---

## Factor de Bayes

	
Por lo tanto,
	
$$\frac{\alpha_{0}}{\alpha_{1}} = \frac{\mathcal{L}(\theta_0|x)\pi_0}{\mathcal{L}(\theta_1|x)\pi_1}$$
	
$$\Rightarrow B = \frac{\alpha_{0}\pi_{1}}{\alpha_{1}pi_{0}} = \frac{\mathcal{L}(\theta_0|x)}{\mathcal{L}(\theta_1|x)} = \lambda$$
	
En otras palabras, $B$ equivale a la razón de verosimilitudes de $H_0$ con respecto a $H_1$, la cual usualmente es interpretada como los odds de $H_0$ con respecto a $H_1$ dados por los datos, incluso por estadísticos frecuentistas. Sin embargo, cuando las hipótesis no son simples resulta que el factor de Bayes es distinto al estadístico de la razón de verosimilitudes pues este cubre todos los posibles valores de $\theta$ en $\Omega_{0}$ y $\Omega_{1}$ en lugar de solo tomar en cuenta sus estimadores máximo verosímiles.
	
Si $B > 1$ esto indica que $H_0$ es más apoyado por los datos que $H_1$ mientras que si $B < 1$ entonces los datos apoyan más a $H_1$ que a $H_0$. El Cuadro 2 presenta la escala que desarrolló Jeffreys, enmendada por Kass y Raftery, para medir la magnitud del apoyo a $H_0$ o $H_1$.

---

## Factor de Bayes

	
Escala de evidencia de Jeffreys para el factor de Bayes

Factor de Bayes    | Interpretación                  |
-------------------|---------------------------------|
$B < 1/150$        |  Evidencia muy fuerte para $H_1$|
$1/150 < B < 1/20$ |  Evidencia fuerte para $H_1$    |
$1/20 < B < 1/3$   |  Evidencia moderada para $H_1$  |
$1/3 < B < 1$      |  Evidencia débil para $H_1$     | 
$1 < B < 3$        |  Evidencia débil para $H_0$     |
$3 < B < 20$       |  Evidencia moderada para $H_0$  |
$20 < B < 150$     |  Evidencia fuerte para $H_0$    |
$B > 150$          |  Evidencia muy fuerte para $H_0$|

---

## Factor de Bayes


Ejemplo: Retornemos al ejemplo de los apartamentos donde $\theta$ solo podía tomar los valores 2, 2.5 y 3. Supongamos que se quiere contrastar las hipótesis $H_0: \theta = 2$ contra $H_1: \theta > 2$. 

Solución: Como ya para ese ejemplo obtuvimos la función de probabilidad a posteriori entonces podemos calcular las probabilidades de cada hipótesis:
	
$$\alpha_0 = P(\theta = 2|x) = 0.416$$
$$\alpha_1 = P(\theta > 2 | x) = P(\theta = 2.5|x) + P(\theta = 3|x) = 0.311 + 0.273 = 0.584 = 1 - \alpha_0$$ 

---

## Factor de Bayes

	
Comparando únicamente estos dos valores vemos que preferimos a $H_1$ sobre $H_0$. Si fuésemos a calcular el factor de Bayes entonces vamos a necesitar los odds a priori a posteriori. Estos vienen dados por
	
$$\frac{\pi_{0}}{\pi_{1}} = \frac{\pi_0}{1-\pi_0} = \frac{0.50}{0.50} = 1$$

$$\frac{\alpha_{0}}{\alpha_{1}} = \frac{\alpha_{0}}{1-\alpha_{0}} = \frac{0.416}{0.584} = 0.713$$
	
$$\Rightarrow B = \frac{0.713}{1} = 0.713$$

Es decir, tenemos que los odds de $H_0$ a posteriori disminuyeron un $28.7\%$ al pasar de la información a priori a la información a posteriori. Es decir, nuestros datos brindaron evidencia a favor de la hipótesis alterna. Viendo la escala del Cuadro 2 vemos que en este caso tenemos evidencia débil a favor de $H_1$. 

---

## Factor de Bayes

	
Ejemplo: Sea $X_1 , X_2 , X_3 , X_4$ una muestra aleatoria tal que $X_j \sim N(\mu, 1)$. Suponiendo que se utilizó una priori Uniforme(0,30) para $\mu$ y quieren contrastar las hipótesis $H_{0}: \mu \geq 14$ contra $H_{1}: \mu < 14$, encuentre el factor de Bayes. Suponga que de la muestra se obtuvo que $\overline{x} = 15.3$. 
	
Solución: Sabemos que con esta priori entonces $\mu|x \sim N\left( \overline{x},\frac{1}{n}\right)$, por lo tanto con los datos que observamos de la muestra tenemos que
	
$$\mu|x \sim N(15.3; 0.25 )$$
	
Ya que conocemos la priori y la posteriori de $\mu$ debemos calcular las probabilidades de las hipótesis a prioi y a posteriori. Como la priori es una uniforme entonces tenemos que $\pi_0 = P(\mu \geq 14) = \frac{30-14}{30} = 0.533$. Por lo tanto se cumple que $\pi_1 = P(\mu < 14) = 1 - \pi_0 = 0.467$. Por lo tanto, los odds a priori son $\frac{0.533}{0.467} = 1.143$. 

---

## Factor de Bayes

	
Ahora calculamos las probabilidades a posteriori. Como la distribución a posteriori es una Normal vamos a tener que estandarizar para poder calcular probabilidades mediante la tabla de la normal estándar (o usar la calculadora o R). Por lo tanto tenemos que la probabilidad a posteriori de $H_0$ viene dada por $\alpha_{0} = P(\mu \geq 14 | x) = P\left( Z \geq 2(14-15.3) | x \right) = 1 - P(Z < -2.6) = 0.9953$. Por consiguiente tenemos que $\alpha_{1} = 0.0047$ y los odds a posteriori son $213.5376$.
	 
Esto significa que el factor de Bayes sería $\frac{213.5376}{1.143} = 186.8454$ el cual, según la escala de Jeffreys, muestra evidencia muy fuerte a favor de $H_0$. 

---

# Ejercicios de práctica
	
* Ejercicios al final del handout de Mauricio.
* No olviden hacer los ejercicios extras que están en mediación



---

class: center, middle

# ¿Qué discutimos hoy?

Distribuciones previas o a previa. Estadística Bayesiana: inferencia (estimación puntual, intervalos de credibilidad y factores de Bayes).

# ¿Qué nos falta para terminar el curso?

El quiz del martes (4to trabajo) y el proyecto de Bayes. El espacio para enviar el link está en Mediación Virtual.



Slides creadas via R package [**xaringan**](https://github.com/yihui/xaringan).

