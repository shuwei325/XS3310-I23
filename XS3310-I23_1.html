<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>XS3310 Teoría Estadística</title>
    <meta charset="utf-8" />
    <meta name="author" content="Escuela de Estadística" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# XS3310 Teoría Estadística
]
.subtitle[
## I Semetre 2023
]
.author[
### Escuela de Estadística
]
.date[
### 14-03-2023
]

---





## Bienvenida

### Shu Wei Chu Chen

* Profesor adjunto (3er año invitado) en la Escuela de Estadística (UCR)
* Bach. en Estadística (UCR)
* MSc. en Estadística (UCR)
* PhD. en Estadística (Universidad de São Paulo)


### Áreas de interés

* Teoría Estadística (frecuentista y Bayesiana).
* Series temporales.
* Análisis espacio-temporal.
* Ciencia de Datos.

---

## Bienvenida
### Acerca de ustedes

* Compartan su nombre, año de carrera, por lo menos un objetivo específico que quieran alcanzar al finalizar este curso, y algo que gusten compartir con la clase.

---

## Información importante


**[Mediación Virtual](https://mv1.mediacionvirtual.ucr.ac.cr/course/view.php?id=21179)**


**[Programa del curso](http://www.estadistica.ucr.ac.cr/images/EEST/Programas/Bachi/2022/IC/Programa-XS-3310.pdf)**


**Pendientes para ustedes:**


* [Llenar el formulario]()


---

class: center, middle

## Hasta ahora en la carrera de Estadística:

En medio del auge de ciencia de datos, datos grandes, y tantas puertas que la tecnología nos ha abierto.


&lt;div class="figure"&gt;
&lt;img src="figs/ciencia_de_datos.png" alt="Ciencia de Datos vs Estadística." width="100%" /&gt;
&lt;p class="caption"&gt;Ciencia de Datos vs Estadística.&lt;/p&gt;
&lt;/div&gt;




---

class: center, middle

# Hasta ahora en la carrera de Estadística:

 ¿Qué vimos en modelos probabilísticos discretos y contínuos? 

## https://seeing-theory.brown.edu



---

# ¿Para qué necesitamos Teoría Estadística?

Necesitamos entender el porqué los resultados teóricos funcionan. 

Es decir, si tomamos el promedio de un conjunto de dato, 

- ¿Es el mejor estimador que podemos generar? 
- ¿Qué significa mejor?
- ¿Puedo probar que efectivamente es el mejor?



---

## Repaso de Inferencia Estadística

- Variable aleatoria (v.a.)
- Muestra aleatoria (m.a.)
- Parámetro
- Estadístico
- Estimador 
- Modos de convergencia 
- Ley de lo grandes números 
- Teorema del límite central


---


## Parámetros, estadísticos y estimadores
	
### Variable aleatoria (v.a.)	

Una variable aleatoria (v.a.) `\({\displaystyle X}\)` es una función real definida en el espacio de probabilidad `\({\displaystyle (\Omega ,{\mathcal {A}},P)}\)`, asociado a un experimento aleatorio.

&gt; `\({\displaystyle X:\Omega \to \mathbb {R} }\)`

### Muestra aleatoria (m.a.)

Sean `\(X_{1}, X_{2}, ... , X_{n}\)` un conjunto de variables aleatorias (v.a.) independientes e idénticamente distribuidas; este conjunto se denomina *muestra aleatoria* de una población infinita.

---

## Parámetros, estadísticos y estimadores

### Parámetro

Es una característica de la población. Algunos parámetros de interés podría ser la media, varianza o la proporción en una población.

### Estadístico

Es una función de la muestra aleatoria, `\(T=f\left(X_{1}, X_{2}, ... , X_{n}\right)\)`. Un estadístico es a su vez una variable aleatoria y como tal tiene su propia distribución, denominada distribución muestral, con sus parámetros correspondientes.

---

## Parámetros, estadísticos y estimadores

### Estimador

Cuando un estadístico, llámese `\(\hat{\theta}\)`, se utiliza para aproximar el valor de un parámetro `\(\theta\)`, entonces se acostumbra llamar a ese estadístico con el nombre de estimador.

&gt; **Notación:** `\(\theta\)` parámetro a estimar.

&gt; `\(\hat{\theta}\)` estimador de `\(\theta\)`.

### Ejemplo:

* `\(\bar{X}\)` es un estimador de `\(\mu\)`
* `\(S^2\)` es un estimador de `\(\sigma^2\)`
* `\(\hat{p}\)` es un estimador de `\(p\)`
* `\(\hat{\theta}=\frac{X_1+X_n}{2}\)` es un estimador de `\(\mu\)`

---

## Modos de convergencia 

## Desigualdad de Markov  

Si `\(X\)` es una v.a. tal que  `\(\operatorname{Pr}(X \geq 0)=1\)`. Entonces para cada número real  `\(t&gt;0\)`, se tiene que 

`\begin{equation}
\operatorname{Pr}(X \geq t) \leq \frac{E(X)}{t}
\end{equation}`

## Desigualdad de Chebyshev 

Si  `\(X\)` es una v.a. que cumple que  `\(\operatorname{Var}(X)\)` existe. Entonces para cada número  `\(t&gt;0\)`

$$
\operatorname{Pr}(|X-E(X)| \geq t) \leq \frac{\operatorname{Var}(X)}{t^{2}}
$$
---

## Modos de convergencia 

## Propiedades de la media muestral 

Sea `\(X_{1}, \ldots, X_{n}\)` una v.a. con una  distribución con media  `\(\mu\)` y varianza `\(\sigma^{2}\)`. Sea  `\(\bar{X}_{n}\)` la media muestral. Entonces,  `\(E\left(\overline{X}_{n}\right)=\mu\)` y `\(\operatorname{Var}\left(\bar{X}_{n}\right)=\sigma^{2} / n\)`

## Convergencia en probabilidad 

Decimos que  `\(Z_{1}, Z_{2}, \ldots\)` de v.a. converge a `\(b\)` en probabilidad si para cada número  `\(\varepsilon&gt;0\)`,

`$$\lim _{n \rightarrow \infty} \operatorname{Pr}\left(\left|Z_{n}-b\right|&lt;\varepsilon\right)=1$$`

Esta propiedad se denota como

$$
Z_{n} \stackrel{p}{\longrightarrow} b.
$$
---
## Parámetros, estadísticos y estimadores 
### Ley de los grandes números 

Suponga que  `\(X_{1}, \ldots, X_{n}\)` es una muestra de una distribución con media `\(\mu\)` y varianza finita. Sea  `\(\bar{X}_{n}\)` la media muestral. Entonces, 
`\begin{equation*}
\bar{X}_{n} \stackrel{p}{\longrightarrow} \mu
\end{equation*}`

¿Cómo se puede probar este resultado usando la desigualdad de Chebyshev?


---
## Parámetros, estadísticos y estimadores 
### Convergencia en distribución 

Suponga que se tienen una secuencia de funciones de distribución `\(F_1, \ldots, F_n\)` para la muestra `\(X_1,\ldots,X_n\)`. Se dice que `\(X_1,\ldots,X_n,\ldots\)`  converge en distribución a `\(X*\)`, cuya función de distribución es `\(F^*\)`, si 


`\begin{equation*}
\lim _{n \rightarrow \infty} F_{n}(x)=F^{*}(x)
\end{equation*}`
Se denota también como 
`\begin{equation*}
X_n \stackrel{d}{\longrightarrow} X^*
\end{equation*}`

### Teorema del límite central

Si `\(X_1,\ldots, X_n\)` es una muestra aleatoria de tamaño `\(n\)`, y la distribución tiene media `\(\mu\)` y varianza `\(\sigma^2&lt;0\)`. Entonces se cumple que 

`$$Z_{n} = \frac{\overline{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \stackrel{d}{\longrightarrow} N\left(0,1\right) \quad si\quad n \rightarrow \infty$$`
o lo que es equivalente 
`\(\overline{X} \xrightarrow{\text{d}} N\left(\mu, \frac{\sigma^2}{n}\right) \quad si\quad n \rightarrow \infty.\)`
---
## Relaciones entre los modos de convergencia 

Se puede probar que 
`\begin{equation*}
\text{Convergencia en Probabilidad} \implies \text{Convergencia en distribución}
\end{equation*}`

Para un resumen más detallado, les dejo este video donde se explica mucho mejor

https://www.youtube.com/watch?v=bTMnnrw0v2Y

---

&lt;!-- ## Parámetros, estadísticos y estimadores --&gt;

&lt;!-- ### Ejemplo: --&gt;

&lt;!-- 1. Media muestral: `\(\bar{X} =\frac{\sum_{i=1}^n{ {X}_i } }{n}\)` --&gt;

&lt;!-- Se sabe que `\(\displaystyle E\left(\bar{X}\right)=\mu\)` y `\(\displaystyle Var\left(\bar{X}\right)=\frac{\sigma^2}{n}\)`, donde `\(\mu\)` y `\(\sigma^2\)` son la media y variancia poblacional.  --&gt;

&lt;!-- La distribución de `\(\bar{X}\)` va a depender de la distribución de la población. No obstante, con muestras grandes podemos hacer uso del Teorema del Límite Central, el cual dice: --&gt;

&lt;!-- `$$Z_{n} = \frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \xrightarrow{\text{d}} N\left(0,1\right) \quad si\quad n \rightarrow \infty$$` --&gt;

&lt;!-- O lo que es equivalente a decir que `\(\bar{X} \xrightarrow{\text{d}} N\left(\mu, \frac{\sigma^2}{n}\right) \quad si\quad n \rightarrow \infty\)`. --&gt;

&lt;!-- --- --&gt;

## Parámetros, estadísticos y estimadores
	
### Varianza muestral

 `$$S^{2} = \frac{\sum{\left(X_{j}-\bar{X}\right)^2}}{n-1}$$`

Podemos demostrar que `\(E\left(S^2\right)=\sigma^2\)` y `\(Var\left(S^2\right)=\frac{2\sigma^4}{n-1}\)`.


En la sección siguiente, probaremos que si la población es `\(N\left(\mu,\sigma^2\right)\)`, entonces, `$$\displaystyle \frac{\left(n-1\right)S^2}{\sigma^2} \sim \chi^{2}_\left(n-1\right).$$` 
Además sabemos que el valor esperado de una `\(\chi^2\)` son sus grados de libertad y la varianza son dos veces los grados de libertad. Por lo tanto,
F
$$ E\left(\frac{\left(n-1\right)S^2}{\sigma^2}\right) = n-1  \\
    \Rightarrow \frac{\left(n-1\right)E\left(S^2\right)}{\sigma^2} = n-1 \\
	  \Rightarrow E\left(S^2\right) = \sigma^2 $$

---

## Parámetros, estadísticos y estimadores
	

Podemos hacer lo mismo para encontrar la varianza cuando la población es Normal:

$$  Var\left(\frac{\left(n-1\right)S^2}{\sigma^2}\right) = 2\left(n-1\right) $$ 

$$ \Rightarrow \frac{\left(n-1\right)^2}{\sigma^4}Var\left(S^2\right) = 2\left(n-1\right) \\
\Rightarrow Var\left(S^2\right) = \frac{2\sigma^4}{n-1} $$
---
## Parámetros, estadísticos y estimadores

En realidad la distribución `\(\chi^2\)` es la distribución muestral de `\(S^2\)`. O sea que si se extraen todas las muestras posibles de una población normal y a cada muestra se le calcula su varianza, se obtendrá la distribución muestral de varianzas.

Para estimar la varianza poblacional o la desviación estándar, se necesita conocer el estadístico `\(X^2\)`. Si se elige una muestra de tamaño `\(n\)` de una población normal con varianza `\(\sigma^2\)`, el estadístico:

`$$X^2= \displaystyle \frac{(n-1)S^2}{\sigma^2}$$`

tiene una distribución muestral que es una distribución `\(\chi^2\)` con `\(gl= n-1\)` grados de libertad, es decir, `$$\displaystyle \frac{\left(n-1\right)S^2}{\sigma^2} \sim \chi^{2}_\left(n-1\right)$$`. 




---

class: center, middle

# ¡Gracias!

Slides creadas via R package [**xaringan**](https://github.com/yihui/xaringan).

El chakra viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
